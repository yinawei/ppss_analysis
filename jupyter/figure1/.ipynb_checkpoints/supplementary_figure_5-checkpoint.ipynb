{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec1804-243e-4f81-b1c5-a790e9e0f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from utils.utils import *\n",
    "from utils.ccf_utils import *\n",
    "from scipy import stats, spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from math import log\n",
    "from scipy.special import logsumexp\n",
    "from scipy.optimize import minimize_scalar\n",
    "# from scipy import optimize, stats\n",
    "\n",
    "from scipy.stats import norm, lognorm, beta, poisson\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "major_list = ['Isocortex', 'OLF','HPF', 'CTXsp', 'STR',\n",
    "              'PAL','TH', 'HY', 'MB', 'P','MY', 'CBX',]\n",
    "\n",
    "import json\n",
    "with open('../../data/region2primaryRegion.json', 'r') as f:\n",
    "    detailRegion2rough = json.load(f)\n",
    "\n",
    "# =========================\n",
    "# 1) 截断分布的PMF集合\n",
    "# =========================\n",
    "\n",
    "def _normalize_trunc(probs):\n",
    "    s = probs.sum()\n",
    "    return probs / s if s > 0 else probs\n",
    "\n",
    "def pmf_trunc_poisson(k, lam):\n",
    "    raw = stats.poisson.pmf(k, mu=lam)\n",
    "    return raw\n",
    "\n",
    "def pmf_trunc_nbinom(k, r, p):\n",
    "    # r>0, p∈(0,1). SciPy 负二项参数化：nbinom(r, p) 为 “成功概率p、需要r次成功前失败数”的分布，支持0,1,2...\n",
    "    # 我们直接取 k 的概率并截断归一化\n",
    "    raw = stats.nbinom.pmf(k, n=r, p=p)\n",
    "    return raw\n",
    "\n",
    "def pmf_trunc_geom(k, p):\n",
    "    # 几何分布支持从1开始：P(K=k) = (1-p)^(k-1) * p\n",
    "    raw = (1 - p) ** (k - 1) * p\n",
    "    return raw\n",
    "\n",
    "def pmf_trunc_logseries(k, theta):\n",
    "    # 对数级数：P(K=k) = -1/ln(1-theta) * theta^k / k, k>=1, 0<theta<1\n",
    "    # 直接依式计算并截断归一化\n",
    "    raw = -1.0 / np.log(1 - theta) * (theta ** k) / k\n",
    "    return raw\n",
    "\n",
    "def pmf_trunc_dlognorm(k, mu, sigma):\n",
    "    # 离散对数正态：用连续Lognormal在半整数区间积分近似\n",
    "    # 概率 ~ CDF(k+0.5) - CDF(k-0.5)，k>=1\n",
    "    # 注意：sigma>0\n",
    "    k = np.asarray(k)\n",
    "    lo = np.maximum(0.5, k - 0.5)  # 下界不小于0.5\n",
    "    hi = k + 0.5\n",
    "    cdf = stats.lognorm.cdf\n",
    "    raw = cdf(hi, s=sigma, scale=np.exp(mu)) - cdf(lo, s=sigma, scale=np.exp(mu))\n",
    "    return raw\n",
    "\n",
    "# 统一接口：返回k_min..k_max上的截断概率\n",
    "def truncated_probs(model, params, k_min=1, k_max=10):\n",
    "    k = np.arange(k_min, k_max + 1)\n",
    "    if model == \"poisson\":\n",
    "        raw = pmf_trunc_poisson(k, params[\"lam\"])\n",
    "    elif model == \"nbinom\":\n",
    "        raw = pmf_trunc_nbinom(k, params[\"r\"], params[\"p\"])\n",
    "    elif model == \"geom\":\n",
    "        raw = pmf_trunc_geom(k, params[\"p\"])\n",
    "    elif model == \"logseries\":\n",
    "        raw = pmf_trunc_logseries(k, params[\"theta\"])\n",
    "    elif model == \"dlognorm\":\n",
    "        raw = pmf_trunc_dlognorm(k, params[\"mu\"], params[\"sigma\"])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    return _normalize_trunc(raw)\n",
    "\n",
    "# =========================\n",
    "# 2) 拟合：最小化交叉熵/负对数似然\n",
    "# =========================\n",
    "\n",
    "def _cross_entropy(p_obs, p_model, eps=1e-12):\n",
    "    p_model = np.clip(p_model, eps, 1.0)  # 避免log(0)\n",
    "    return -np.sum(p_obs * np.log(p_model))\n",
    "\n",
    "def _fit_model(observed_probs, model, k_min=1, k_max=10):\n",
    "    # 根据模型设置参数与边界；目标函数 = 交叉熵（等价于用比例做的NLL/样本数）\n",
    "    if model == \"poisson\":\n",
    "        x0 = [max(0.1, np.dot(np.arange(k_min, k_max+1), observed_probs))]  # 初值≈均值\n",
    "        bounds = [(1e-3, 50)]\n",
    "        def unpack(x): return {\"lam\": x[0]}\n",
    "    elif model == \"nbinom\":\n",
    "        x0 = [1.5, 0.5]        # r, p\n",
    "        bounds = [(1e-3, 100), (1e-4, 1-1e-4)]\n",
    "        def unpack(x): return {\"r\": x[0], \"p\": x[1]}\n",
    "    elif model == \"geom\":\n",
    "        x0 = [0.3]\n",
    "        bounds = [(1e-4, 1-1e-4)]\n",
    "        def unpack(x): return {\"p\": x[0]}\n",
    "    elif model == \"logseries\":\n",
    "        x0 = [0.7]\n",
    "        bounds = [(1e-4, 1-1e-4)]\n",
    "        def unpack(x): return {\"theta\": x[0]}\n",
    "    elif model == \"dlognorm\":\n",
    "        # 用log(k)的均值方差来给mu/sigma初值\n",
    "        ks = np.arange(k_min, k_max+1)\n",
    "        m = np.sum(observed_probs * np.log(ks + 1e-9))\n",
    "        v = np.sum(observed_probs * (np.log(ks + 1e-9) - m)**2)\n",
    "        x0 = [m, max(0.3, np.sqrt(max(v, 1e-6)))]\n",
    "        bounds = [(-5, 5), (1e-3, 5)]\n",
    "        def unpack(x): return {\"mu\": x[0], \"sigma\": x[1]}\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "\n",
    "    def objective(x):\n",
    "        params = unpack(x)\n",
    "        p_model = truncated_probs(model, params, k_min, k_max)\n",
    "        return _cross_entropy(observed_probs, p_model)\n",
    "\n",
    "    res = minimize(objective, x0=x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "    return unpack(res.x), res.fun, res.success, res\n",
    "\n",
    "# =========================\n",
    "# 3) 评估指标：KL/AIC/BIC/卡方\n",
    "# =========================\n",
    "\n",
    "def evaluate_model(observed_probs, model_probs, num_params, total_count=None):\n",
    "    \"\"\"\n",
    "    observed_probs: 观测比例(和为1)\n",
    "    model_probs:    模型概率(和为1)\n",
    "    num_params:     模型参数个数\n",
    "    total_count:    若提供（观测总样本数/突触总数），AIC/BIC和卡方将用它进行尺度化\n",
    "    \"\"\"\n",
    "    ce = _cross_entropy(observed_probs, model_probs)        # 交叉熵\n",
    "    kl = ce - (-np.sum(observed_probs * np.log(np.clip(observed_probs,1e-12,1.0))))  # KL(obs||model)\n",
    "\n",
    "    # AIC/BIC 需要总样本数来计算NLL = N * CE\n",
    "    if total_count is not None and total_count > 0:\n",
    "        nll = total_count * ce\n",
    "        aic = 2 * num_params + 2 * nll\n",
    "        bic = num_params * log(total_count) + 2 * nll\n",
    "        # 卡方检验（期望频数 = N * model_probs）\n",
    "        obs_counts = observed_probs * total_count\n",
    "        exp_counts = model_probs * total_count\n",
    "        # 为避免0格，做一个轻微平滑\n",
    "        exp_counts = np.clip(exp_counts, 1e-8, None)\n",
    "        chi2_stat = ((obs_counts - exp_counts)**2 / exp_counts).sum()\n",
    "        dof = (len(model_probs) - 1 - num_params)\n",
    "        p_value = 1 - stats.chi2.cdf(chi2_stat, max(dof,1))\n",
    "    else:\n",
    "        aic = bic = None\n",
    "        chi2_stat = p_value = None\n",
    "\n",
    "    return {\n",
    "        \"CE\": ce,\n",
    "        \"KL\": kl,\n",
    "        \"AIC\": aic,\n",
    "        \"BIC\": bic,\n",
    "        \"chi2\": chi2_stat,\n",
    "        \"chi2_p\": p_value\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# 4) 一键拟合与模型选择\n",
    "# =========================\n",
    "\n",
    "def fit_and_compare(observed, k_min=1, k_max=10, total_count=None):\n",
    "    \"\"\"\n",
    "    observed: 可以是概率(和为1)或频数(自动归一)\n",
    "    total_count: 若传入频数则可省略；若传入概率但你知道总样本数，填这里以开启AIC/BIC/卡方\n",
    "    \"\"\"\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    if not np.isclose(observed.sum(), 1.0):\n",
    "        if observed.sum() <= 0:\n",
    "            raise ValueError(\"Observed data must be positive.\")\n",
    "        if total_count is None:\n",
    "            total_count = observed.sum()\n",
    "        observed_probs = observed / observed.sum()\n",
    "    else:\n",
    "        observed_probs = observed\n",
    "        # total_count 可由用户单独提供（若需要AIC/BIC/卡方）\n",
    "\n",
    "    models = [\n",
    "        (\"poisson\",   1),\n",
    "        (\"nbinom\",    2),\n",
    "        (\"geom\",      1),\n",
    "        (\"logseries\", 1),\n",
    "        (\"dlognorm\",  2),\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    for name, kparams in models:\n",
    "        params, ce, ok, raw = _fit_model(observed_probs, name, k_min, k_max)\n",
    "        p_model = truncated_probs(name, params, k_min, k_max)\n",
    "        metrics = evaluate_model(observed_probs, p_model, kparams, total_count)\n",
    "        results[name] = {\n",
    "            \"params\": params,\n",
    "            \"probs\": p_model,\n",
    "            \"CE\": metrics[\"CE\"],\n",
    "            \"KL\": metrics[\"KL\"],\n",
    "            \"AIC\": metrics[\"AIC\"],\n",
    "            \"BIC\": metrics[\"BIC\"],\n",
    "            \"chi2\": metrics[\"chi2\"],\n",
    "            \"chi2_p\": metrics[\"chi2_p\"],\n",
    "            \"opt_success\": ok\n",
    "        }\n",
    "\n",
    "    # 选择准则：优先 BIC（若有N），否则 KL（或CE）\n",
    "    if any(results[m][\"BIC\"] is not None for m in results):\n",
    "        best = min(results.items(), key=lambda kv: kv[1][\"BIC\"] if kv[1][\"BIC\"] is not None else np.inf)\n",
    "    else:\n",
    "        best = min(results.items(), key=lambda kv: kv[1][\"KL\"])\n",
    "\n",
    "    best_name, best_info = best\n",
    "    return best_name, best_info, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec1e36-0488-4ca0-8898-4d5d6822e993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de024e-76df-45a4-adcc-a1f86301e71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soma_feature = pd.read_csv('../../data/155k_DEN_soma_feature.csv', \n",
    "                           sep=',', index_col=0)\n",
    "# soma_feature.set_index('swc_id', inplace=True)\n",
    "soma_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d06dc0c-d4ac-465f-81f0-bfc36681d600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7b9f7-ccab-4112-8b3a-3e48e928348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "den_contact = pd.read_csv('../../data/ppss_from_pacs.csv', sep=',', index_col=0)\n",
    "\n",
    "den_contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e58c0b-e1ba-4784-9350-c37c0c9a2f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d548-a248-40ae-8cb9-900d003433ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soma_feature = soma_feature.loc[den_contact['target_cell'].unique(), :]\n",
    "soma_feature = soma_feature[soma_feature['source_region'].isin(list(den_contact['target_region'].unique()))].copy()\n",
    "soma_ct = soma_feature['source_region'].value_counts()\n",
    "del soma_ct['fiber tracts']\n",
    "# soma_ct = soma_ct[0:15]\n",
    "soma_ct = soma_ct[soma_ct>=30]\n",
    "soma_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c93e6-70a7-4f41-b190-6e22635e06bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9db31-ea69-4eb1-9724-4e14d5f87881",
   "metadata": {},
   "outputs": [],
   "source": [
    "sele_region = detailRegion2rough.keys()\n",
    "order_list = []\n",
    "\n",
    "for i in sele_region:\n",
    "    if i in list(soma_ct.index):\n",
    "        order_list.append(i)\n",
    "\n",
    "# order_list = ['MOp', 'MOs', 'SSp-n', 'SSp-bfd', 'SSs', 'AUDp', \n",
    "#               'VISp', 'CA1', 'DG', 'POST', 'CP', 'OT', 'MEA', \n",
    "#               'GPe', 'BST', 'VPL', 'VPM', 'LGd', 'SNr', 'MRN',\n",
    "#               'PAG']\n",
    "\n",
    "print(order_list)\n",
    "print(len(order_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608c8e0-f667-48d9-83f4-6393fec01467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d87cd188-0347-49f4-9603-f8f7f10ee3a7",
   "metadata": {},
   "source": [
    "## branch-level distribution in same source regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e1b9f-390d-48fb-9a89-96772d6ed342",
   "metadata": {},
   "outputs": [],
   "source": [
    "den_contact = den_contact[den_contact['target_region'].isin(order_list)]\n",
    "den_contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f568a8-2d89-4f0d-8b5e-412ac24aafd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bc164-226d-486c-9127-86dd7f263657",
   "metadata": {},
   "outputs": [],
   "source": [
    "den_contact.loc[:, 'count'] = 1\n",
    "\n",
    "wide_df2_ = den_contact.pivot_table(index='target_region', columns=['branch_level'], \n",
    "                        values=['count'], aggfunc='sum', fill_value=0\n",
    "                       )\n",
    "\n",
    "wide_df2_.columns.name = ''\n",
    "wide_df2_.columns = [i[1] for i in wide_df2_.columns]\n",
    "wide_df2_.index.name = ''\n",
    "wide_df2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27483ef-36a2-41ad-9a5c-ccd83d12564b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb12c2-7a64-4b3d-af43-fc983e42dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df2 = wide_df2_.copy()\n",
    "\n",
    "for i in wide_df2.index:\n",
    "   wide_df2.loc[i, :] = wide_df2.loc[i, :] / soma_ct[i]\n",
    "\n",
    "wide_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c891d-2b9e-478f-8380-2eccf05bbdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d7402-3229-4ed1-97fa-6d461a498ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide_df2 = wide_df2.loc[:, list(range(1, 11))]\n",
    "# # wide_df2 = (wide_df2.T / wide_df2.sum(axis=1)).T\n",
    "# wide_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ca07a-ce6a-46ac-95ee-0b63606b72a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8943e-b58e-4547-848e-3ff6f0557e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, max(wide_df2.columns)+1):\n",
    "    if i not in list(wide_df2.columns):\n",
    "        wide_df2[i] = 0\n",
    "\n",
    "wide_df2 = wide_df2.loc[order_list, list(range(1, 11))]\n",
    "wide_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e256c-17e3-42bd-a85e-671e5833d1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35154c63-8dfb-46ea-afac-20565f3ddee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_df1 = pd.DataFrame()\n",
    "test_models = ['poisson', 'nbinom', 'geom', \n",
    "               'logseries', 'dlognorm']\n",
    "\n",
    "for i in tqdm(wide_df2.index):\n",
    "    tmp_observed_counts = wide_df2.loc[i, :]\n",
    "    \n",
    "    tmp_total_N = tmp_observed_counts.sum()\n",
    "    tmp_observed_probs = tmp_observed_counts / tmp_total_N\n",
    "    \n",
    "    best_name, best_info, all_results = fit_and_compare(\n",
    "        tmp_observed_probs, k_min=1, k_max=10, total_count=tmp_total_N\n",
    "    )\n",
    "\n",
    "    lambda_df1 = pd.concat([lambda_df1, \n",
    "                           pd.DataFrame({'region': [i]*len(test_models), \n",
    "                                         'dist': test_models, \n",
    "                                         'BIC': [all_results[m]['BIC'] for m in test_models]\n",
    "                                         }), \n",
    "                          ], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "lambda_df1['major_region'] = lambda_df1['region'].map(detailRegion2rough)\n",
    "lambda_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb2d12-b7e2-4614-9e49-4d87652ca6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = lambda_df1.loc[lambda_df1.groupby('major_region')['BIC'].idxmin()].reset_index(drop=True)\n",
    "prop_table = pd.crosstab(best_df['major_region'],\n",
    "                         best_df['dist'],\n",
    "                         normalize='index') \n",
    "\n",
    "prop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e969a4-e78a-4d56-8698-5941e55a9341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in np.unique(lambda_df1.region.unique()):\n",
    "    tmp_df = lambda_df1[lambda_df1['region']==i]\n",
    "    tmp_min = np.min(tmp_df['BIC'])\n",
    "    print(tmp_df.loc[tmp_df['BIC']==tmp_min, 'dist'])\n",
    "    results.append(tmp_df.loc[tmp_df['BIC']==tmp_min, 'dist'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd192d-6833-49fd-9727-b7bceab85ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4525c74-d452-4cb6-abd1-333021ddf5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57945915-1825-40a0-9734-15dcb00f7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_trunc(probs):\n",
    "    s = probs.sum()\n",
    "    return probs / s if s > 0 else probs\n",
    "\n",
    "def pmf_trunc_poisson(k, lam):\n",
    "    raw = stats.poisson.pmf(k, mu=lam)\n",
    "    return raw\n",
    "\n",
    "def truncated_probs(model, params, k_min=1, k_max=10):\n",
    "    k = np.arange(k_min, k_max + 1)\n",
    "    if model == \"poisson\":\n",
    "        raw = pmf_trunc_poisson(k, params[\"lam\"])\n",
    "    return _normalize_trunc(raw)\n",
    "\n",
    "def _cross_entropy(p_obs, p_model, eps=1e-12):\n",
    "    p_model = np.clip(p_model, eps, 1.0)\n",
    "    return -np.sum(p_obs * np.log(p_model))\n",
    "\n",
    "def _fit_model(observed_probs, model, k_min=1, k_max=10):\n",
    "    if model == \"poisson\":\n",
    "        x0 = [max(0.1, np.dot(np.arange(k_min, k_max+1), observed_probs))]\n",
    "        bounds = [(1e-3, 50)]\n",
    "        def unpack(x): return {\"lam\": x[0]}\n",
    "    def objective(x):\n",
    "        params = unpack(x)\n",
    "        p_model = truncated_probs(model, params, k_min, k_max)\n",
    "        return _cross_entropy(observed_probs, p_model)\n",
    "\n",
    "    res = minimize(objective, x0=x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "    return unpack(res.x), res.fun, res.success, res\n",
    "\n",
    "def fit_model(observed, k_min=1, k_max=10):\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "    if not np.isclose(observed.sum(), 1.0):\n",
    "        if observed.sum() <= 0:\n",
    "            raise ValueError(\"Observed data must be positive.\")\n",
    "\n",
    "        observed_probs = observed / observed.sum()\n",
    "    else:\n",
    "        observed_probs = observed\n",
    "        \n",
    "    params, ce, ok, raw = _fit_model(observed_probs, 'poisson', k_min, k_max)\n",
    "    p_model = truncated_probs('poisson', params, k_min, k_max)\n",
    "    return params, p_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fa80a-6c4a-4348-a1fb-63083c2a556d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160bd0e6-991f-461a-a2e1-0a0dff20f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df2 = wide_df2_.copy()\n",
    "\n",
    "for i in wide_df2.index:\n",
    "   wide_df2.loc[i, :] = wide_df2.loc[i, :] / soma_ct[i]\n",
    "    \n",
    "wide_df2 = (wide_df2.T / wide_df2.sum(axis=1)).T\n",
    "wide_df2 = wide_df2.loc[:, list(range(1, 11))]\n",
    "wide_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3aa41-1c4f-4d6b-93bd-8cf79f6f322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "for i in wide_df2.index:\n",
    "    if detailRegion2rough[i] == 'STR':\n",
    "        tmp_list.append(i)\n",
    "\n",
    "best_lambda, model_fit = fit_model(wide_df2.loc[tmp_list].mean(), )\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(2*np.arange(1,11) - 0.4, \n",
    "        wide_df2.loc[tmp_list].mean(),\n",
    "        color='royalblue'\n",
    "       )\n",
    "plt.bar(2*np.arange(1,11) + 0.4, \n",
    "        model_fit, \n",
    "        color='grey'\n",
    "       )\n",
    "plt.xticks(np.arange(2, 22, 2))\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2])\n",
    "plt.ylim([0, 0.22])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('./STR.svg', bbox_inches='tight')\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af4164-bade-4cfe-bc22-69e79a63afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "for i in wide_df2.index:\n",
    "    if detailRegion2rough[i] == 'Isocortex':\n",
    "        tmp_list.append(i)\n",
    "\n",
    "best_lambda, model_fit = fit_model(wide_df2.loc[tmp_list].mean(), )\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(2*np.arange(1,11) - 0.4, \n",
    "        wide_df2.loc[tmp_list].mean(),\n",
    "        color='royalblue'\n",
    "       )\n",
    "plt.bar(2*np.arange(1,11) + 0.4, \n",
    "        model_fit, \n",
    "        color='grey'\n",
    "       )\n",
    "plt.xticks(np.arange(2, 22, 2))\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2])\n",
    "plt.ylim([0, 0.22])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('./Iso.svg', bbox_inches='tight')\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce872697-8696-4f2e-9f4f-0fd2c0d07150",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "for i in wide_df2.index:\n",
    "    if detailRegion2rough[i] == 'TH':\n",
    "        tmp_list.append(i)\n",
    "\n",
    "best_lambda, model_fit = fit_model(wide_df2.loc[tmp_list].mean(), )\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(2*np.arange(1,11) - 0.4, \n",
    "        wide_df2.loc[tmp_list].mean(),\n",
    "        color='royalblue'\n",
    "       )\n",
    "plt.bar(2*np.arange(1,11) + 0.4, \n",
    "        model_fit, \n",
    "        color='grey'\n",
    "       )\n",
    "plt.xticks(np.arange(2, 22, 2))\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2])\n",
    "plt.ylim([0, 0.22])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('./TH.svg', bbox_inches='tight')\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37d577-5d84-498f-8c36-31a203670da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_df2 = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(wide_df2.index):\n",
    "    tmp_observed_probs = wide_df2.loc[i, :]\n",
    "    best_lambda, model_fit = fit_model(tmp_observed_probs, )\n",
    "    first_order_ju = np.sum(tmp_observed_probs*tmp_observed_probs.index)\n",
    "    second_order_ju = np.sum(tmp_observed_probs*tmp_observed_probs.index*tmp_observed_probs.index) - (first_order_ju)**2\n",
    "    \n",
    "    lambda_df2 = pd.concat([lambda_df2, \n",
    "                           pd.DataFrame({'region': [i], 'best_lambda': [best_lambda['lam']], \n",
    "                                         'u1': [first_order_ju], 'u2': [second_order_ju],\n",
    "                                         'fitted_probs': [model_fit]}), \n",
    "                          ], axis=0)\n",
    "    \n",
    "lambda_df2['major_region'] = lambda_df2['region'].map(detailRegion2rough)\n",
    "lambda_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5318da-d3a8-4c35-b11c-9a39436f2c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_df2['u1/u2'] = lambda_df2['u1'] / lambda_df2['u2']\n",
    "lambda_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8adc462-fe63-481a-aed5-9eccd0f97e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_df2 = lambda_df2.reset_index(drop=True)\n",
    "f,ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "ax = sns.boxplot(data=lambda_df2, x='major_region', \n",
    "            y='u1', \n",
    "            order=['Isocortex', 'OLF', 'STR', 'HY', 'MB', 'P',\n",
    "                   'CTXsp', 'PAL', 'HPF', 'TH', 'MB'],\n",
    "            palette='tab20',\n",
    "            flierprops={\n",
    "                'marker': 'd',\n",
    "                'markerfacecolor': 'k',\n",
    "                'markeredgecolor': 'k',\n",
    "                'markersize': 6\n",
    "            }\n",
    "           )\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title('first-order moment: Expectation')\n",
    "plt.ylabel('Expectation')\n",
    "plt.ylim([2.3, 6.9])\n",
    "plt.savefig('./first-order moment_all_regions.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e72a1-993f-4540-b6ff-098330aa9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "ax = sns.boxplot(data=lambda_df2, x='major_region', \n",
    "            y='u2', \n",
    "            palette='tab20',\n",
    "            order=['Isocortex', 'OLF', 'STR', 'HY', 'MB', 'P',\n",
    "                   'CTXsp', 'PAL', 'HPF', 'TH', 'MB'],\n",
    "            flierprops={\n",
    "                'marker': 'd',\n",
    "                'markerfacecolor': 'k',\n",
    "                'markeredgecolor': 'k',\n",
    "                'markersize': 6\n",
    "            }\n",
    "           )\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title('second-order moment: variance')\n",
    "plt.ylabel('variance')\n",
    "plt.ylim([0, 8.5])\n",
    "plt.savefig('./second-order moment variance_all_regions.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f909e-8644-4ead-b631-21569054dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "ax = sns.boxplot(data=lambda_df2, x='major_region', \n",
    "            y='u1/u2', \n",
    "            palette='tab20',\n",
    "            order=['Isocortex', 'OLF', 'STR', 'HY', 'MB', 'P',\n",
    "                   'CTXsp', 'PAL', 'HPF', 'TH', 'MB'],\n",
    "            fliersize=0,\n",
    "            flierprops={\n",
    "                'marker': 'd',\n",
    "                'markerfacecolor': 'k',\n",
    "                'markeredgecolor': 'k',\n",
    "                'markersize': 6\n",
    "            },\n",
    "            showfliers=False\n",
    "           )\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title('first-order vs second-order')\n",
    "plt.ylabel('u1 / u2')\n",
    "# plt.ylim([0.5, 2])\n",
    "plt.savefig('./cmp_moment_all_regions.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3819b-17bd-4c27-ac54-d18db4a32406",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "ax=sns.boxplot(data=lambda_df2, x='major_region', \n",
    "            y='best_lambda', \n",
    "            palette='tab20',\n",
    "            order=['Isocortex', 'OLF', 'STR', 'HY', 'MB', 'P',\n",
    "                   'CTXsp', 'PAL', 'HPF', 'TH', 'MB'],\n",
    "            flierprops={\n",
    "                'marker': 'd',\n",
    "                'markerfacecolor': 'k',\n",
    "                'markeredgecolor': 'k',\n",
    "                'markersize': 6\n",
    "            }\n",
    "           )\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylim([1, 7.8])\n",
    "\n",
    "plt.savefig('./best_lambda_all_regions.svg', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb90112-895c-4a90-8516-1f24737ee4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f998da6-dbe8-4888-8da7-4a4dd615700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5ba82-14fd-4274-ac04-ccc22cab0cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
